{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e835fdce",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a36a1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from decision_tree import DecisionTree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0d36ff1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions des données d'entraînement: (120, 5)\n",
      "Dimensions des données de test: (30, 5)\n",
      "\n",
      "Quelques premières lignes des données d'entraînement:\n",
      "    sepal length (cm)  sepal width (cm)  ...  petal width (cm)  label\n",
      "22                4.6               3.6  ...               0.2      0\n",
      "15                5.7               4.4  ...               0.4      0\n",
      "65                6.7               3.1  ...               1.4      1\n",
      "11                4.8               3.4  ...               0.2      0\n",
      "42                4.4               3.2  ...               0.2      0\n",
      "\n",
      "[5 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "feature_names = iris.feature_names\n",
    "target_names = iris.target_names\n",
    "\n",
    "data_df = pd.DataFrame(X, columns=feature_names)\n",
    "data_df['label'] = y\n",
    "\n",
    "train_df, test_df = train_test_split(data_df, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Dimensions des données d'entraînement: {train_df.shape}\")\n",
    "print(f\"Dimensions des données de test: {test_df.shape}\")\n",
    "print(\"\\nQuelques premières lignes des données d'entraînement:\")\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01718ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entraînement de l'arbre de décision...\n",
      "Entraînement terminé.\n"
     ]
    }
   ],
   "source": [
    "my_decision_tree = DecisionTree(feature_names=feature_names, target_names=target_names)\n",
    "\n",
    "print(\"Entraînement de l'arbre de décision avec profondeur maximale...\")\n",
    "my_decision_tree.fit(train_df)\n",
    "print(\"Entraînement terminé.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6b501865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Visualisation de l'arbre de décision entraîné ---\n",
      "Est-ce que petal width (cm) >= 1.000?\n",
      "--> Vrai:\n",
      "  Est-ce que petal length (cm) >= 4.800?\n",
      "  --> Vrai:\n",
      "    Est-ce que petal width (cm) >= 1.800?\n",
      "    --> Vrai:\n",
      "      Est-ce que petal length (cm) >= 4.900?\n",
      "      --> Vrai:\n",
      "        Prédit: {'virginica': 1.0}\n",
      "      --> Faux:\n",
      "        Est-ce que sepal width (cm) >= 3.200?\n",
      "        --> Vrai:\n",
      "          Prédit: {'versicolor': 1.0}\n",
      "        --> Faux:\n",
      "          Prédit: {'virginica': 1.0}\n",
      "    --> Faux:\n",
      "      Est-ce que petal length (cm) >= 5.600?\n",
      "      --> Vrai:\n",
      "        Prédit: {'virginica': 1.0}\n",
      "      --> Faux:\n",
      "        Est-ce que sepal width (cm) >= 2.500?\n",
      "        --> Vrai:\n",
      "          Est-ce que petal length (cm) >= 5.100?\n",
      "          --> Vrai:\n",
      "            Est-ce que petal width (cm) >= 1.600?\n",
      "            --> Vrai:\n",
      "              Prédit: {'versicolor': 1.0}\n",
      "            --> Faux:\n",
      "              Prédit: {'virginica': 1.0}\n",
      "          --> Faux:\n",
      "            Prédit: {'versicolor': 1.0}\n",
      "        --> Faux:\n",
      "          Prédit: {'virginica': 1.0}\n",
      "  --> Faux:\n",
      "    Est-ce que petal width (cm) >= 1.700?\n",
      "    --> Vrai:\n",
      "      Prédit: {'virginica': 1.0}\n",
      "    --> Faux:\n",
      "      Prédit: {'versicolor': 1.0}\n",
      "--> Faux:\n",
      "  Prédit: {'setosa': 1.0}\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Visualisation de l'arbre de décision entraîné ---\")\n",
    "my_decision_tree.print_tree()\n",
    "print(\"------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42f0d3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Évaluation des Performances ---\n",
      "\n",
      "Sur l'ensemble d'entraînement:\n",
      "Exactitude (Accuracy): 1.0000\n",
      "Précision (Precision) (weighted): 1.0000\n",
      "Rappel (Recall) (weighted): 1.0000\n",
      "F1-Score (weighted): 1.0000\n",
      "\n",
      "Sur l'ensemble de test:\n",
      "Exactitude (Accuracy): 1.0000\n",
      "Précision (Precision) (weighted): 1.0000\n",
      "Rappel (Recall) (weighted): 1.0000\n",
      "F1-Score (weighted): 1.0000\n",
      "\n",
      "Rapport de classification sur l'ensemble de test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       1.00      1.00      1.00         9\n",
      "   virginica       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, precision_score, recall_score\n",
    "\n",
    "X_train = train_df.drop('label', axis=1)\n",
    "y_train_true = train_df['label'].values\n",
    "\n",
    "X_test = test_df.drop('label', axis=1)\n",
    "y_test_true = test_df['label'].values\n",
    "\n",
    "y_train_pred = my_decision_tree.predict(X_train)\n",
    "\n",
    "y_test_pred = my_decision_tree.predict(X_test)\n",
    "\n",
    "print(\"\\n--- Évaluation des Performances ---\")\n",
    "\n",
    "print(\"\\nSur l'ensemble d'entraînement:\")\n",
    "print(f\"Exactitude (Accuracy): {accuracy_score(y_train_true, y_train_pred):.4f}\")\n",
    "print(f\"Précision (Precision) (weighted): {precision_score(y_train_true, y_train_pred, average='weighted', zero_division=0):.4f}\")\n",
    "print(f\"Rappel (Recall) (weighted): {recall_score(y_train_true, y_train_pred, average='weighted', zero_division=0):.4f}\")\n",
    "print(f\"F1-Score (weighted): {f1_score(y_train_true, y_train_pred, average='weighted', zero_division=0):.4f}\")\n",
    "\n",
    "print(\"\\nSur l'ensemble de test:\")\n",
    "print(f\"Exactitude (Accuracy): {accuracy_score(y_test_true, y_test_pred):.4f}\")\n",
    "print(f\"Précision (Precision) (weighted): {precision_score(y_test_true, y_test_pred, average='weighted', zero_division=0):.4f}\")\n",
    "print(f\"Rappel (Recall) (weighted): {recall_score(y_test_true, y_test_pred, average='weighted', zero_division=0):.4f}\")\n",
    "print(f\"F1-Score (weighted): {f1_score(y_test_true, y_test_pred, average='weighted', zero_division=0):.4f}\")\n",
    "\n",
    "print(\"\\nRapport de classification sur l'ensemble de test:\")\n",
    "target_names_str = [str(name) for name in target_names]\n",
    "print(classification_report(y_test_true, y_test_pred, target_names=target_names_str, zero_division=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eye-of-emergency (3.10.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
