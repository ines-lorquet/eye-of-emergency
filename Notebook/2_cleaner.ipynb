{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2a290af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from text_mining import TextMining\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5e9de7",
   "metadata": {},
   "source": [
    "### Importer le CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "27635f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6478 entries, 0 to 6477\n",
      "Data columns (total 19 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   keyword                  6422 non-null   object \n",
      " 1   location                 4332 non-null   object \n",
      " 2   text                     6478 non-null   object \n",
      " 3   target                   6478 non-null   int64  \n",
      " 4   stop_word_count          6478 non-null   int64  \n",
      " 5   mean_word_length         6478 non-null   float64\n",
      " 6   char_count               6478 non-null   int64  \n",
      " 7   punctuation_count        6478 non-null   int64  \n",
      " 8   hashtag_count            6478 non-null   int64  \n",
      " 9   presence_url             6478 non-null   int64  \n",
      " 10  hashtags                 1501 non-null   object \n",
      " 11  mentions                 1689 non-null   object \n",
      " 12  urls                     3497 non-null   object \n",
      " 13  tokens                   6478 non-null   object \n",
      " 14  clean_text               6471 non-null   object \n",
      " 15  has_top10_hashtag        6478 non-null   int64  \n",
      " 16  has_top10_keyword        6478 non-null   int64  \n",
      " 17  has_top_bigram           6478 non-null   int64  \n",
      " 18  nb_words_in_cooc_class1  6478 non-null   int64  \n",
      "dtypes: float64(1), int64(10), object(8)\n",
      "memory usage: 961.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/final_test.csv', index_col=False)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39130f5",
   "metadata": {},
   "source": [
    "### Traitement des valeurs nuls ou non pertinentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "02cab5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "387d3516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6478, 19)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6478 entries, 0 to 6477\n",
      "Data columns (total 19 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   keyword                  6422 non-null   object \n",
      " 1   location                 4332 non-null   object \n",
      " 2   text                     6478 non-null   object \n",
      " 3   target                   6478 non-null   int64  \n",
      " 4   stop_word_count          6478 non-null   int64  \n",
      " 5   mean_word_length         6478 non-null   float64\n",
      " 6   char_count               6478 non-null   int64  \n",
      " 7   punctuation_count        6478 non-null   int64  \n",
      " 8   hashtag_count            6478 non-null   int64  \n",
      " 9   presence_url             6478 non-null   int64  \n",
      " 10  hashtags                 1501 non-null   object \n",
      " 11  mentions                 1689 non-null   object \n",
      " 12  urls                     3497 non-null   object \n",
      " 13  tokens                   6478 non-null   object \n",
      " 14  clean_text               6471 non-null   object \n",
      " 15  has_top10_hashtag        6478 non-null   int64  \n",
      " 16  has_top10_keyword        6478 non-null   int64  \n",
      " 17  has_top_bigram           6478 non-null   int64  \n",
      " 18  nb_words_in_cooc_class1  6478 non-null   int64  \n",
      "dtypes: float64(1), int64(10), object(8)\n",
      "memory usage: 1012.2+ KB\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792b6963",
   "metadata": {},
   "source": [
    "### Gestion  des valeurs manquantes\n",
    "\n",
    "Au lieu de supprimer 33% des données avec `dropna()`, considérons cette approche :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d9f971",
   "metadata": {},
   "source": [
    "### Proportion target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0ff86436",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = df[df['target'] == 0]\n",
    "df_1 = df[df['target'] == 1]\n",
    "\n",
    "df_0_sampled = df_0.sample(n=len(df_1), random_state=42)\n",
    "\n",
    "df = pd.concat([df_0_sampled, df_1], axis=0).sample(frac=1, random_state=42)  # shuffle le tout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3735ce77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.5\n",
       "1    0.5\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1df627a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6478 entries, 4249 to 6441\n",
      "Data columns (total 19 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   keyword                  6422 non-null   object \n",
      " 1   location                 4332 non-null   object \n",
      " 2   text                     6478 non-null   object \n",
      " 3   target                   6478 non-null   int64  \n",
      " 4   stop_word_count          6478 non-null   int64  \n",
      " 5   mean_word_length         6478 non-null   float64\n",
      " 6   char_count               6478 non-null   int64  \n",
      " 7   punctuation_count        6478 non-null   int64  \n",
      " 8   hashtag_count            6478 non-null   int64  \n",
      " 9   presence_url             6478 non-null   int64  \n",
      " 10  hashtags                 6478 non-null   object \n",
      " 11  mentions                 6478 non-null   object \n",
      " 12  urls                     6478 non-null   object \n",
      " 13  tokens                   6478 non-null   object \n",
      " 14  clean_text               6478 non-null   object \n",
      " 15  has_top10_hashtag        6478 non-null   int64  \n",
      " 16  has_top10_keyword        6478 non-null   int64  \n",
      " 17  has_top_bigram           6478 non-null   int64  \n",
      " 18  nb_words_in_cooc_class1  6478 non-null   int64  \n",
      "dtypes: float64(1), int64(10), object(8)\n",
      "memory usage: 1012.2+ KB\n"
     ]
    }
   ],
   "source": [
    "tm = TextMining(df, text_column=\"text\")\n",
    "df_clean = (\n",
    "    tm.lowercase()\n",
    "      .remove_accents()\n",
    "      .extract_target_char(\"#\", \"hashtags\")\n",
    "      .extract_target_char(\"@\", \"mentions\")\n",
    "      .extract_url()\n",
    "      .clean_regex([\"text\"])\n",
    "      .tokenize()\n",
    "      .remove_stopwords()\n",
    "      .remove_short_tokens()\n",
    "      .apply_lemmatizer()\n",
    "      .build_clean_text()\n",
    "      .get_df()\n",
    ")\n",
    "# df_clean.to_csv()\n",
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6326165d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>stop_word_count</th>\n",
       "      <th>mean_word_length</th>\n",
       "      <th>char_count</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>hashtag_count</th>\n",
       "      <th>presence_url</th>\n",
       "      <th>tokens</th>\n",
       "      <th>has_top10_hashtag</th>\n",
       "      <th>has_top10_keyword</th>\n",
       "      <th>has_top_bigram</th>\n",
       "      <th>nb_words_in_cooc_class1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4249</th>\n",
       "      <td>there are people who plotted against me that a...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[people, plotted, still, wondering, survived]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>windstorm board oks rate hike before change</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.272727</td>\n",
       "      <td>90</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[windstorm, board, ok, rate, hike, change]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5349</th>\n",
       "      <td>the road to success is paved with pennies that...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4.588235</td>\n",
       "      <td>94</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[road, success, paved, penny, flattened, train...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1631</th>\n",
       "      <td>just thought i d let you all know it s probabl...</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>4.320000</td>\n",
       "      <td>132</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[thought, let, know, probably, good, idea, plu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4523</th>\n",
       "      <td>rt america rt rt com eye of super typhoon soud...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8.214286</td>\n",
       "      <td>128</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[america, com, eye, super, typhoon, soudelor, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>families to sue over legionnaires more than 40...</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6.611111</td>\n",
       "      <td>136</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[family, sue, legionnaire, family, affected, f...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>faan orders evacuation of abandoned aircraft a...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>87</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[faan, order, evacuation, abandoned, aircraft,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>sorry for screaming at you and from the car i ...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>4.619048</td>\n",
       "      <td>117</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[sorry, screaming, car, kinda, know, people, l...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4390</th>\n",
       "      <td>police unions retard justice amp drain gov but...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4.680000</td>\n",
       "      <td>141</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[police, union, retard, justice, amp, drain, g...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>carmike cinemas on antioch shooting we are gra...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>137</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[carmike, cinema, antioch, shooting, grateful,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  target  \\\n",
       "4249  there are people who plotted against me that a...       0   \n",
       "91          windstorm board oks rate hike before change       0   \n",
       "5349  the road to success is paved with pennies that...       0   \n",
       "1631  just thought i d let you all know it s probabl...       0   \n",
       "4523  rt america rt rt com eye of super typhoon soud...       1   \n",
       "260   families to sue over legionnaires more than 40...       1   \n",
       "313   faan orders evacuation of abandoned aircraft a...       0   \n",
       "995   sorry for screaming at you and from the car i ...       0   \n",
       "4390  police unions retard justice amp drain gov but...       0   \n",
       "652   carmike cinemas on antioch shooting we are gra...       1   \n",
       "\n",
       "      stop_word_count  mean_word_length  char_count  punctuation_count  \\\n",
       "4249                9          4.714286          79                  0   \n",
       "91                  1          7.272727          90                  8   \n",
       "5349                9          4.588235          94                  2   \n",
       "1631               14          4.320000         132                  7   \n",
       "4523                2          8.214286         128                 17   \n",
       "260                 7          6.611111         136                 10   \n",
       "313                 2          7.000000          87                  6   \n",
       "995                10          4.619048         117                  8   \n",
       "4390                3          4.680000         141                  9   \n",
       "652                 5          6.666667         137                 10   \n",
       "\n",
       "      hashtag_count  presence_url  \\\n",
       "4249              0             0   \n",
       "91                3             1   \n",
       "5349              0             0   \n",
       "1631              0             0   \n",
       "4523              0             1   \n",
       "260               1             1   \n",
       "313               0             1   \n",
       "995               0             0   \n",
       "4390              0             0   \n",
       "652               0             1   \n",
       "\n",
       "                                                 tokens  has_top10_hashtag  \\\n",
       "4249      [people, plotted, still, wondering, survived]                  0   \n",
       "91           [windstorm, board, ok, rate, hike, change]                  0   \n",
       "5349  [road, success, paved, penny, flattened, train...                  0   \n",
       "1631  [thought, let, know, probably, good, idea, plu...                  0   \n",
       "4523  [america, com, eye, super, typhoon, soudelor, ...                  0   \n",
       "260   [family, sue, legionnaire, family, affected, f...                  0   \n",
       "313   [faan, order, evacuation, abandoned, aircraft,...                  0   \n",
       "995   [sorry, screaming, car, kinda, know, people, l...                  0   \n",
       "4390  [police, union, retard, justice, amp, drain, g...                  0   \n",
       "652   [carmike, cinema, antioch, shooting, grateful,...                  0   \n",
       "\n",
       "      has_top10_keyword  has_top_bigram  nb_words_in_cooc_class1  \n",
       "4249                  0               0                        0  \n",
       "91                    0               0                        0  \n",
       "5349                  0               0                        0  \n",
       "1631                  0               0                        0  \n",
       "4523                  0               0                        0  \n",
       "260                   1               0                        1  \n",
       "313                   0               0                        0  \n",
       "995                   0               0                        0  \n",
       "4390                  0               0                        0  \n",
       "652                   0               0                        0  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = df_clean[[c for c in df_clean.columns \n",
    "                    if df_clean[c].dtype != 'object' or c in ['text', 'tokens']]]\n",
    "\n",
    "df_clean.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c045c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_clean.to_csv(\"test_to_suli.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eye-of-emergency",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
