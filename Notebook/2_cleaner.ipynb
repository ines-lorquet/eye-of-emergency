{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a290af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from text_mining import TextMining\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5e9de7",
   "metadata": {},
   "source": [
    "### Importer le CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27635f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/train_tweets_processed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39130f5",
   "metadata": {},
   "source": [
    "### Traitement des valeurs nuls ou non pertinentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02cab5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "387d3516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7613, 11)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7613 entries, 0 to 7612\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   id                 7613 non-null   int64  \n",
      " 1   keyword            7552 non-null   object \n",
      " 2   location           5080 non-null   object \n",
      " 3   text               7613 non-null   object \n",
      " 4   target             7613 non-null   int64  \n",
      " 5   word_count         7613 non-null   int64  \n",
      " 6   stop_word_count    7613 non-null   int64  \n",
      " 7   url_count          7613 non-null   int64  \n",
      " 8   mean_word_length   7613 non-null   float64\n",
      " 9   char_count         7613 non-null   int64  \n",
      " 10  punctuation_count  7613 non-null   int64  \n",
      "dtypes: float64(1), int64(7), object(3)\n",
      "memory usage: 713.7+ KB\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "078faccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5080, 11)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5080 entries, 31 to 7581\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   id                 5080 non-null   int64  \n",
      " 1   keyword            5080 non-null   object \n",
      " 2   location           5080 non-null   object \n",
      " 3   text               5080 non-null   object \n",
      " 4   target             5080 non-null   int64  \n",
      " 5   word_count         5080 non-null   int64  \n",
      " 6   stop_word_count    5080 non-null   int64  \n",
      " 7   url_count          5080 non-null   int64  \n",
      " 8   mean_word_length   5080 non-null   float64\n",
      " 9   char_count         5080 non-null   int64  \n",
      " 10  punctuation_count  5080 non-null   int64  \n",
      "dtypes: float64(1), int64(7), object(3)\n",
      "memory usage: 476.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "print(df.shape) \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792b6963",
   "metadata": {},
   "source": [
    "### Gestion  des valeurs manquantes\n",
    "\n",
    "Au lieu de supprimer 33% des données avec `dropna()`, considérons cette approche :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "102c7c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données conservées de location : 5080 lignes (vs 5080 avec dropna)\n",
      "Pourcentage conservé : 66.7%\n",
      "Données conservées de keyword : 5080 lignes (vs 5080 avec dropna)\n",
      "Pourcentage conservé : 66.7%\n"
     ]
    }
   ],
   "source": [
    "def replace_missing_values(series, default_value):\n",
    "    df[series] = df[series].fillna(default_value)\n",
    "\n",
    "    print(f\"Données conservées de {series} : {df.shape[0]} lignes (vs {df.shape[0]} avec dropna)\")\n",
    "    print(f\"Pourcentage conservé : {df.shape[0]/7613*100:.1f}%\")\n",
    "\n",
    "replace_missing_values('location', \"\")\n",
    "replace_missing_values('keyword', \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a6b2b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>word_count</th>\n",
       "      <th>stop_word_count</th>\n",
       "      <th>url_count</th>\n",
       "      <th>mean_word_length</th>\n",
       "      <th>char_count</th>\n",
       "      <th>punctuation_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>48</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>@bbcmtd Wholesale Markets ablaze http://t.co/l...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>55</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>49</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Est. September 2012 - Bristol</td>\n",
       "      <td>We always try to bring the heavy. #metal #RT h...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>67</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>50</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>AFRICA</td>\n",
       "      <td>#AFRICANBAZE: Breaking news:Nigeria flag set a...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.222222</td>\n",
       "      <td>82</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>52</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>Crying out for more! Set me ablaze</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>53</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>London, UK</td>\n",
       "      <td>On plus side LOOK AT THE SKY LAST NIGHT IT WAS...</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4.923077</td>\n",
       "      <td>76</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id keyword                       location  \\\n",
       "31  48  ablaze                     Birmingham   \n",
       "32  49  ablaze  Est. September 2012 - Bristol   \n",
       "33  50  ablaze                         AFRICA   \n",
       "34  52  ablaze               Philadelphia, PA   \n",
       "35  53  ablaze                     London, UK   \n",
       "\n",
       "                                                 text  target  word_count  \\\n",
       "31  @bbcmtd Wholesale Markets ablaze http://t.co/l...       1           5   \n",
       "32  We always try to bring the heavy. #metal #RT h...       0          10   \n",
       "33  #AFRICANBAZE: Breaking news:Nigeria flag set a...       1           9   \n",
       "34                 Crying out for more! Set me ablaze       0           7   \n",
       "35  On plus side LOOK AT THE SKY LAST NIGHT IT WAS...       0          13   \n",
       "\n",
       "    stop_word_count  url_count  mean_word_length  char_count  \\\n",
       "31                0          1         10.200000          55   \n",
       "32                3          1          5.800000          67   \n",
       "33                1          1          8.222222          82   \n",
       "34                3          0          4.000000          34   \n",
       "35                5          1          4.923077          76   \n",
       "\n",
       "    punctuation_count  \n",
       "31                  6  \n",
       "32                  8  \n",
       "33                  9  \n",
       "34                  1  \n",
       "35                  5  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ea0176d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.567717\n",
       "1    0.432283\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d9f971",
   "metadata": {},
   "source": [
    "### Proportion target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ff86436",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = df[df['target'] == 0]\n",
    "df_1 = df[df['target'] == 1]\n",
    "\n",
    "df_0_sampled = df_0.sample(n=len(df_1), random_state=42)\n",
    "\n",
    "df = pd.concat([df_0_sampled, df_1], axis=0).sample(frac=1, random_state=42)  # shuffle le tout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3735ce77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.5\n",
       "0    0.5\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b1b7f6",
   "metadata": {},
   "source": [
    "### Nettoyage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b04036",
   "metadata": {},
   "source": [
    "- Conversion en minuscules\n",
    "- Suppression des URL\n",
    "- mentions et hashtags\n",
    "- Suppression de la ponctuation et caractères spéciaux\n",
    "- Tokenisation\n",
    "- Suppression des stopwords\n",
    "- Lemmatisation (ou stemming)\n",
    "- Vectorisation des textes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9522ef4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>word_count</th>\n",
       "      <th>stop_word_count</th>\n",
       "      <th>url_count</th>\n",
       "      <th>mean_word_length</th>\n",
       "      <th>char_count</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6818</th>\n",
       "      <td>[t, r, a, p, p, e, d]</td>\n",
       "      <td>[b, o, m, b,  , h, e, a, d,  ,  , e, x, p, l, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5.428571</td>\n",
       "      <td>134</td>\n",
       "      <td>1</td>\n",
       "      <td>[bomb, head, explosive, decisions, dat, produc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4842</th>\n",
       "      <td>[m, a, s, s,  , 2, 0, m, u, r, d, e, r]</td>\n",
       "      <td>[o, k, a, y,  , n, o, t,  , s, u, r, e,  , t, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>5.421053</td>\n",
       "      <td>121</td>\n",
       "      <td>8</td>\n",
       "      <td>[okay, sure, word, mass, murder, applies, war,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5848</th>\n",
       "      <td>[r, u, i, n]</td>\n",
       "      <td>[l, i, k, e,  , w, h, y,  , o, n,  , e, a, r, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>101</td>\n",
       "      <td>2</td>\n",
       "      <td>[like, earth, would, want, anybody, unhappy, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1851</th>\n",
       "      <td>[c, r, u, s, h]</td>\n",
       "      <td>[m, y,  , w, o, m, a, n,  , c, r, u, s, h,  , ...</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8.083333</td>\n",
       "      <td>108</td>\n",
       "      <td>8</td>\n",
       "      <td>[woman, crush, wedneday, goes, beautiful, love...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5729</th>\n",
       "      <td>[r, e, s, c, u, e, r, s]</td>\n",
       "      <td>[ ,  ,  , m, a, n, y,  , d, e, a, t, h, s,  , ...</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6.611111</td>\n",
       "      <td>136</td>\n",
       "      <td>14</td>\n",
       "      <td>[many, deaths, shipwreck, rescuers, trying, sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>[b, u, r, n, e, d]</td>\n",
       "      <td>[m, e, t, a, l,  , c, u, t, t, i, n, g,  , s, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>139</td>\n",
       "      <td>7</td>\n",
       "      <td>[metal, cutting, sparks, brush, fire, brighton...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5719</th>\n",
       "      <td>[r, e, s, c, u, e, r, s]</td>\n",
       "      <td>[v, i, d, e, o,  ,  ,  , w, e,  , r, e,  , p, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>6.611111</td>\n",
       "      <td>136</td>\n",
       "      <td>13</td>\n",
       "      <td>[video, picking, bodies, water, rescuers, sear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4988</th>\n",
       "      <td>[m, i, l, i, t, a, r, y]</td>\n",
       "      <td>[m, i, k, e,  , m, a, g, n, e, r,  , d, i, s, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.083333</td>\n",
       "      <td>108</td>\n",
       "      <td>10</td>\n",
       "      <td>[mike, magner, discusses, trust, betrayed, via...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7282</th>\n",
       "      <td>[w, h, i, r, l, w, i, n, d]</td>\n",
       "      <td>[s, e, t,  , a,  , n, e, w,  , r, e, c, o, r, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>139</td>\n",
       "      <td>9</td>\n",
       "      <td>[set, new, record, 7, states, 4, days, even, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6918</th>\n",
       "      <td>[t, r, o, u, b, l, e]</td>\n",
       "      <td>[t, r, o, u, b, l, e,  , t, r, o, u, b, l, e, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>44</td>\n",
       "      <td>5</td>\n",
       "      <td>[trouble, trouble, get, way]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      keyword  \\\n",
       "6818                    [t, r, a, p, p, e, d]   \n",
       "4842  [m, a, s, s,  , 2, 0, m, u, r, d, e, r]   \n",
       "5848                             [r, u, i, n]   \n",
       "1851                          [c, r, u, s, h]   \n",
       "5729                 [r, e, s, c, u, e, r, s]   \n",
       "1295                       [b, u, r, n, e, d]   \n",
       "5719                 [r, e, s, c, u, e, r, s]   \n",
       "4988                 [m, i, l, i, t, a, r, y]   \n",
       "7282              [w, h, i, r, l, w, i, n, d]   \n",
       "6918                    [t, r, o, u, b, l, e]   \n",
       "\n",
       "                                                   text  target  word_count  \\\n",
       "6818  [b, o, m, b,  , h, e, a, d,  ,  , e, x, p, l, ...       1          21   \n",
       "4842  [o, k, a, y,  , n, o, t,  , s, u, r, e,  , t, ...       1          19   \n",
       "5848  [l, i, k, e,  , w, h, y,  , o, n,  , e, a, r, ...       0          17   \n",
       "1851  [m, y,  , w, o, m, a, n,  , c, r, u, s, h,  , ...       0          12   \n",
       "5729  [ ,  ,  , m, a, n, y,  , d, e, a, t, h, s,  , ...       1          18   \n",
       "1295  [m, e, t, a, l,  , c, u, t, t, i, n, g,  , s, ...       1          21   \n",
       "5719  [v, i, d, e, o,  ,  ,  , w, e,  , r, e,  , p, ...       1          18   \n",
       "4988  [m, i, k, e,  , m, a, g, n, e, r,  , d, i, s, ...       0          12   \n",
       "7282  [s, e, t,  , a,  , n, e, w,  , r, e, c, o, r, ...       0          28   \n",
       "6918  [t, r, o, u, b, l, e,  , t, r, o, u, b, l, e, ...       0           9   \n",
       "\n",
       "      stop_word_count  url_count  mean_word_length  char_count  \\\n",
       "6818                6          0          5.428571         134   \n",
       "4842                8          1          5.421053         121   \n",
       "5848                8          0          5.000000         101   \n",
       "1851                3          1          8.083333         108   \n",
       "5729                5          1          6.611111         136   \n",
       "1295                6          1          5.666667         139   \n",
       "5719                7          1          6.611111         136   \n",
       "4988                1          1          8.083333         108   \n",
       "7282               12          0          4.000000         139   \n",
       "6918                5          0          4.000000          44   \n",
       "\n",
       "      punctuation_count                                             tokens  \n",
       "6818                  1  [bomb, head, explosive, decisions, dat, produc...  \n",
       "4842                  8  [okay, sure, word, mass, murder, applies, war,...  \n",
       "5848                  2  [like, earth, would, want, anybody, unhappy, p...  \n",
       "1851                  8  [woman, crush, wedneday, goes, beautiful, love...  \n",
       "5729                 14  [many, deaths, shipwreck, rescuers, trying, sa...  \n",
       "1295                  7  [metal, cutting, sparks, brush, fire, brighton...  \n",
       "5719                 13  [video, picking, bodies, water, rescuers, sear...  \n",
       "4988                 10  [mike, magner, discusses, trust, betrayed, via...  \n",
       "7282                  9  [set, new, record, 7, states, 4, days, even, k...  \n",
       "6918                  5                       [trouble, trouble, get, way]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean = df.copy()\n",
    "\n",
    "tm = TextMining(data_clean)\n",
    "data_clean = (\n",
    "    tm.lowercase()\n",
    "        .extract_target_char(\"#\", \"hashtags\")\n",
    "        .extract_target_char(\"@\", \"mentions\")\n",
    "        .extract_url()\n",
    "        .clean_regex(['keyword','text', 'location'])\n",
    "        .tokenize()\n",
    "        .remove_stopwords()\n",
    "        .apply_lemmatizer( 'text') # .apply_lemmatizer() ou .apply_stemmer()\n",
    "        .apply_lemmatizer('keyword') # .apply_lemmatizer() ou .apply_stemmer()\n",
    "        .get_df()   \n",
    ")\n",
    "data_clean = data_clean.drop(columns=['hashtags', 'mentions', 'urls', 'location','id'])\n",
    "\n",
    "data_clean.to_csv(\"lemmatizer_tfidf.csv\")\n",
    "data_clean.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f879e186",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TextMining.apply_lemmatizer() missing 1 required positional argument: 'corpus'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m tm \u001b[38;5;241m=\u001b[39m TextMining(df)\n\u001b[1;32m      2\u001b[0m \u001b[43mtm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlowercase\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_target_char\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m#\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhashtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_target_char\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m@\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmentions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclean_regex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkeyword\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlocation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremove_stopwords\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m----> 9\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_lemmatizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \\\n\u001b[1;32m     10\u001b[0m   \u001b[38;5;241m.\u001b[39mvectorize(mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtfidf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Colonnes numériques classiques\u001b[39;00m\n\u001b[1;32m     13\u001b[0m numeric_features \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumber\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# exemple\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: TextMining.apply_lemmatizer() missing 1 required positional argument: 'corpus'"
     ]
    }
   ],
   "source": [
    "tm = TextMining(df)\n",
    "tm.lowercase() \\\n",
    "  .extract_target_char(\"#\", \"hashtags\") \\\n",
    "  .extract_target_char(\"@\", \"mentions\") \\\n",
    "  .extract_url() \\\n",
    "  .clean_regex(['keyword','text', 'location']) \\\n",
    "  .tokenize() \\\n",
    "  .remove_stopwords() \\\n",
    "  .apply_lemmatizer() \\\n",
    "  .vectorize(mode=\"tfidf\")\n",
    "\n",
    "# Colonnes numériques classiques\n",
    "numeric_features = df.select_dtypes(include=\"number\")  # exemple\n",
    "X = np.hstack([tm.X_vectors, numeric_features.values])\n",
    "y = df[\"target\"].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dff8f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4392 entries, 6818 to 2019\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   target             4392 non-null   int64  \n",
      " 1   word_count         4392 non-null   int64  \n",
      " 2   stop_word_count    4392 non-null   int64  \n",
      " 3   url_count          4392 non-null   int64  \n",
      " 4   mean_word_length   4392 non-null   float64\n",
      " 5   char_count         4392 non-null   int64  \n",
      " 6   punctuation_count  4392 non-null   int64  \n",
      " 7   tokens             4392 non-null   object \n",
      "dtypes: float64(1), int64(6), object(1)\n",
      "memory usage: 308.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06037680",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean.to_pickle('lemmatizer_tfidf.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eye-of-emergency (3.10.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
